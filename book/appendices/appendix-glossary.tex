\chapter{Glossary of AI Terms}
\label{appendix:glossary}

\begin{description}

\item[AI (Artificial Intelligence)] Broad term for systems that perform tasks typically requiring human intelligence, such as understanding language, recognizing patterns, and making decisions.

\item[Algorithm] A set of rules or instructions for solving a problem or completing a task. In AI, algorithms determine how systems learn from data.

\item[API (Application Programming Interface)] A way for software systems to communicate. AI tools often offer APIs for integration with other business systems.

\item[Bias] Systematic errors in AI outputs, often reflecting biases present in training data. Can lead to unfair or discriminatory results.

\item[Chatbot] An AI system designed for conversation, often used for customer service or information retrieval.

\item[Classification] An AI task that sorts inputs into predefined categories (e.g., spam vs. not spam, positive vs. negative sentiment).

\item[Context Window] The amount of text an AI model can consider at once. Larger windows enable longer conversations and document analysis. Measured in tokens.

\item[Deep Learning] A type of machine learning using neural networks with many layers. Enables complex pattern recognition in images, language, and other data.

\item[Fine-Tuning] Adapting a pre-trained AI model with additional training on specific data to improve performance on particular tasks.

\item[Foundation Model] A large AI model trained on broad data that can be adapted for many different tasks. GPT-4 and Claude are examples.

\item[Generative AI] AI that creates new content (text, images, code, audio) rather than just analyzing existing content. ChatGPT is a generative AI.

\item[GPT (Generative Pre-trained Transformer)] An architecture for language models developed by OpenAI. The ``GPT'' in ChatGPT.

\item[Hallucination] When AI generates plausible-sounding but false information. A common failure mode requiring human verification.

\item[HITL (Human-in-the-Loop)] A system design where humans review, approve, or correct AI outputs before they are used or published.

\item[LLM (Large Language Model)] AI models trained on vast amounts of text data to understand and generate human language. ChatGPT, Claude, and Gemini are LLMs.

\item[Machine Learning (ML)] AI systems that learn patterns from data rather than being explicitly programmed with rules.

\item[Model] The trained AI system that processes inputs and generates outputs. Different models have different capabilities and limitations.

\item[Natural Language Processing (NLP)] AI techniques for understanding and generating human language. Enables chatbots, translation, and text analysis.

\item[Neural Network] Computing systems inspired by biological neurons. The foundation of modern deep learning and large language models.

\item[Prompt] The input text given to an AI system to generate a response. Prompt quality significantly affects output quality.

\item[Prompt Engineering] The skill of crafting effective prompts to get better AI outputs. Involves specifying role, task, constraints, and context.

\item[RAG (Retrieval Augmented Generation)] A technique that combines AI generation with retrieval from a knowledge base, improving accuracy for specific domains.

\item[Sentiment Analysis] AI analysis that determines the emotional tone of text (positive, negative, neutral).

\item[Temperature] A setting controlling AI output randomness. Higher temperature produces more creative/variable outputs; lower produces more consistent outputs.

\item[Token] The basic unit AI uses to process text. Roughly 4 characters or 3/4 of a word in English. Context windows and pricing are measured in tokens.

\item[Training Data] The data used to train an AI model. The content and quality of training data shapes the model's capabilities and biases.

\item[Transformer] The neural network architecture underlying most modern large language models. Enables processing of long text sequences.

\item[Zero-Shot] Using an AI model for a task without providing examples. Contrast with few-shot (providing a few examples) and fine-tuning (extensive training).

\end{description}
